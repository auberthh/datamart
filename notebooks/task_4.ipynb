{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Modelado Predictivo \n",
    "\n",
    "### By:\n",
    "Auberth Eduardo Hurtado\n",
    "\n",
    "### Date:\n",
    "2025-01-17\n",
    "\n",
    "### Description:\n",
    "\n",
    "Create a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 游닄 Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Load the cleaned_sales_data.csv file from the datamart/data/final directory and inspect the first few rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned sales data\n",
    "sales_data = pd.read_csv(\"../data/final/cleaned_sales_data.csv\")\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 游 1. Realiza un an치lisis exploratorio avanzado: \n",
    "- Identifica estacionalidad y tendencias. \n",
    "- Detecta outliers y eval칰a su impacto en las ventas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying seasonality and trends\n",
    "sales_data['date'] = pd.to_datetime(sales_data['order_date'])\n",
    "data = sales_data.set_index('date')\n",
    "\n",
    "monthly_revenue = data['total_revenue'].resample('ME').sum()\n",
    "monthly_revenue.plot(figsize=(14, 7), title='Monthly Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis by month\n",
    "monthly_decomposition = seasonal_decompose(monthly_revenue, model='additive')\n",
    "# Plot the decomposed components\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(monthly_decomposition.observed, label='Observed')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.plot(monthly_decomposition.trend, label='Trend')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.plot(monthly_decomposition.seasonal, label='Seasonal')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.plot(monthly_decomposition.resid, label='Residual')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result suggests the existence of a stochastic function. In other words, total revenue can be estimated as $Revenue = trend + seasonality - 3.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis by day\n",
    "daily_revenue = data['total_revenue'].resample('D').sum()\n",
    "daily_decomposition = seasonal_decompose(daily_revenue, model='additive', period=365)\n",
    "\n",
    "# Plot the decomposed components\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(daily_decomposition.observed, label='Observed')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.plot(daily_decomposition.trend, label='Trend')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.plot(daily_decomposition.seasonal, label='Seasonal')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.plot(daily_decomposition.resid, label='Residual')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result suggests the existence of no erros. In other words, daily total revenue can be estimated as $trend + seasonality$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection of outliers and evaluation of their impact on sales\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(data=data, x='region', y='total_revenue')\n",
    "plt.title('Boxplot of Total Revenue by Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers have a positive impact by increasing the total revenue in the final estimation. If we exclude the outliers, the average revenue will decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define una estrategia para predecir el ingreso diario total: \n",
    "- Divide los datos en entrenamiento (80%) y prueba (20%). \n",
    "- Implementa modelos: \n",
    "    - Regresi칩n lineal m칰ltiple considerando quantity, price, discount, y region.  \n",
    "    - Modelo basado en Random Forest o Gradient Boosting para capturar relaciones no lineales. \n",
    "- Opcional: Usa t칠cnicas de feature engineering, como generaci칩n de variables temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "data['month'] = data.index.month\n",
    "data['day_of_month'] = data.index.day\n",
    "data['week_of_year'] = data.index.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to dummy variables\n",
    "data = pd.get_dummies(data, columns=['region', 'product_id'], drop_first=True)\n",
    "# for testing purposes other option is use one hot encoder of scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data in train and test sets\n",
    "X = data[['quantity', 'price', 'discount', 'day_of_week', 'month', 'day_of_month', 'week_of_year'] + [col for col in data.columns if 'region_' in col or 'product_id_' in col]]\n",
    "y = data['total_revenue']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head()\n",
    "#X_test.head()\n",
    "#y_train.head()\n",
    "#y_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models implementation\n",
    "\n",
    "# A. Linear regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "\n",
    "# B. Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# C. Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of the test, I have run the models with their default parameters; however, some adjustments could be made to improve the initial comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Eval칰a los modelos usando: \n",
    "- MAE, R^2, y an치lisis de residuales. \n",
    "- Describe el rendimiento y si el modelo es aplicable en un entorno real. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar function to evaluate the models\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f'{model_name} - MAE: {mae:.2f}, R^2: {r2:.2f}')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.residplot(x=y_true, y=y_pred, lowess=True, line_kws={'color': 'red', 'lw': 1})\n",
    "    plt.title(f'Residuals Plot for {model_name}')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar Regresi칩n Lineal M칰ltiple\n",
    "evaluate_model(y_test, y_pred_linear, 'Linear Regression')\n",
    "\n",
    "# Evaluar Random Forest\n",
    "evaluate_model(y_test, y_pred_rf, 'Random Forest')\n",
    "\n",
    "# Evaluar Gradient Boosting\n",
    "evaluate_model(y_test, y_pred_gb, 'Gradient Boosting')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 游눠 Descripci칩n del rendimiento y aplicabilidad en un entorno real\n",
    "Descripci칩n del rendimiento y aplicabilidad en un entorno real:\n",
    "- **La regresi칩n lineal m칰ltiple** puede ser 칰til para relaciones lineales simples, pero puede no capturar todas las complejidades, en este caso se observa que el modelo falla en estimar los ingresos con valores m치s peque침os presentando un problema de heterocedasticidad.\n",
    "- **Random Forest** y **Gradient Boosting** son m치s efectivos para capturar relaciones no lineales y pueden ofrecer mejores predicciones, entre los dos le fue mejor a Random forest al encontrar bajor error en sus estimaciones.\n",
    "- Evaluar el MAE y $R^2$ ayuda a entender la precisi칩n y la capacidad explicativa de los modelos, aunque considero que $R^2$ deber칤a ser revisado como medida de bondad de ajuste al final de todo el proceso pues es muy sensible a los supuestos del modelo, idealmente acompa침arlo con otras medidas como RMSE o MAPE.\n",
    "- En un entorno real, se debe considerar la interpretabilidad del modelo, el tiempo de entrenamiento y la capacidad de generalizaci칩n. El modelo elegible podr칤a ser random forest pero faltar칤a profundizar m치s y examinar otras alternativas como el ajuste de hiperpar치metros u otros modelos m치s idones para este tipo de problemas.\n",
    "\n",
    "----\n",
    "\n",
    "- **Multiple Linear Regression** can be useful for simple linear relationships but may not capture all complexities. In this case, the model struggles to estimate revenues with smaller values, presenting a problem of heteroscedasticity.\n",
    "\n",
    "- **Random Forest** and **Gradient Boosting** are more effective in capturing non-linear relationships and can provide better predictions. Among the two, Random Forest performed better, exhibiting lower error in its estimations.\n",
    "\n",
    "- Evaluating MAE and $R^2$ helps in understanding the accuracy and explanatory power of the models. However $R^2$ should be reviewed as a goodness-of-fit measure at the end of the entire process, as it is very sensitive to the model's assumptions. Ideally, it should be complemented with other measures such as RMSE or MAPE.\n",
    "\n",
    "- In a real-world environment, model interpretability, training time, and generalization capability should be considered. While Random Forest could be a viable model, further exploration and examination of other alternatives, such as hyperparameter tuning or other more suitable models for this type of problem, are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 游눠 Be cautious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final and processed dataset\n",
    "data.to_csv(r'../data/final/final_sales_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "joblib.dump(rf_model, r'../models/random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamart_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
