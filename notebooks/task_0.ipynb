{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 0: GeneraciÃ³n de Datos SintÃ©ticos\n",
    "\n",
    "### By:\n",
    "Auberth Eduardo Hurtado\n",
    "\n",
    "### Date:\n",
    "2025-01-17\n",
    "\n",
    "### Description:\n",
    "\n",
    "Create an artificial dataset by following the steps described in the test. These steps will be performed in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ðŸ“š Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import warnings\n",
    "import matplotlib\n",
    "\n",
    "# Hide warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Escribe un script en Python que genere un conjunto de datos con al menos 50.000 filas siguiendo este esquema: \n",
    "```json\n",
    "{ \n",
    "\"order_id\": \"uuid\", \n",
    "\"customer_id\": \"random_int(1, 10_000)\", \n",
    "\"product_id\": \"random_int(1, 1_000)\", \n",
    "\"quantity\": \"random_int(1, 20)\", \n",
    "\"price\": \"random_float(1.0, 500.0)\", \n",
    "\"discount\": \"random_float(0.0, 0.3)\", \n",
    "\"order_date\": \"random_date(2023-01-01, 2024-12-31)\", \n",
    "\"shipping_priority\": \"random_choice(['Low', 'Medium', \n",
    "'High'])\", \n",
    "\"region\": \"random_choice(['North', 'South', 'East', 'West'])\" \n",
    "}\n",
    "```\n",
    "#### AsegÃºrate de que: \n",
    "- `order_id` sea Ãºnico. \n",
    "- `order_date` estÃ© distribuido con un patrÃ³n de estacionalidad y tendencia creciente (mÃ¡s Ã³rdenes en 2024). \n",
    "- `discount` estÃ© correlacionado inversamente con price. \n",
    "- `shipping_priority` sea proporcional a region (por ejemplo, mÃ¡s alta prioridad en \"North\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¾ Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_rows = 50000\n",
    "max_customer_id = 10000\n",
    "max_product_id = 1000\n",
    "max_quantity = 20\n",
    "max_price = 500\n",
    "max_discount = 0.3\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "noise_percent = 0.05\n",
    "noise_options = ['NULL', -9999, np.nan]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ðŸ‘· 1. Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "- **order_id**: sea Ãºnico.\n",
    "\n",
    "`order_id` is a uuid (Universally Unique Identifier), for that reason I'm going to use the library uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_id = [str(uuid.uuid4()) for _ in range(num_rows)]\n",
    "#print(order_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **customer_id**: random integer between 1 y 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = np.random.randint(1, max_customer_id + 1, num_rows)\n",
    "#print(customer_id.min(), customer_id.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **product_id**: random integer between 1 y 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = np.random.randint(1, max_product_id + 1, num_rows)\n",
    "#print(product_id.min(), product_id.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **quantity**: random integer between 1 y 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity = np.random.randint(1, max_quantity + 1, num_rows)\n",
    "#print(quantity.min(), quantity.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **price**: aleatorio entre 1.0 y 500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = np.random.uniform(1.0, max_price, num_rows)\n",
    "print(price.min(), price.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **discount**: random number between 0.0 and 0.3. It should be inversely correlated with `price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = max_discount - (price / max_price) * max_discount\n",
    "discount = np.clip(discount, 0.0, max_discount)\n",
    "#print(discount.min(), discount.max())\n",
    "#print(\"Correlation between price and discount:\", np.corrcoef(price, discount)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **order_date**: random number between 2023-01-01 and 2024-12-31. Additionally, it should be distributed with a seasonal pattern and an increasing trend (more orders in 2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_weight = {2023: 0.4, 2024: 0.6}\n",
    "\n",
    "def orders_date(start, end, weights):\n",
    "    \"\"\"\n",
    "    Generates a random date between the given start and end dates,\n",
    "    with a seasonal pattern and increasing trend based on year weights.\n",
    "\n",
    "    Parameters:\n",
    "    start (datetime): The start date of the range.\n",
    "    end (datetime): The end date of the range.\n",
    "    weights (dict): A dictionary with years as keys and weights as values,\n",
    "                    indicating the probability of selecting a date in that year.\n",
    "\n",
    "    Returns:\n",
    "    datetime: A random date within the specified range, adjusted according to the year weights.\n",
    "    \"\"\"\n",
    "    date = start + timedelta(days=random.randint(0, int((end - start).days)))\n",
    "    while random.random() > weights[date.year]:\n",
    "        date = start + timedelta(days=random.randint(0, int((end - start).days)))\n",
    "    return date\n",
    "\n",
    "order_date = [orders_date(start_date, end_date, orders_weight) for _ in range(num_rows)]\n",
    "#orders = pd.DataFrame([date.strftime(\"%y-%m\") for date in order_date]).value_counts().sort_index()\n",
    "#orders.plot(kind=\"line\", title=\"Number of Orders per Month\", xlabel=\"Date\", ylabel=\"Number of Orders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **shipping_priority**: random between ['Low', 'Medium', 'High']. Additionally, it should be proportional to `region` (for example, higher priority in \"North\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region: random between: ['North', 'South', 'East', 'West']\n",
    "region = np.random.choice(['North', 'South', 'East', 'West'], num_rows)\n",
    "\n",
    "shipping_priority = np.random.choice(['Low', 'Medium', 'High'], num_rows, p=[0.2, 0.3, 0.5])\n",
    "# Adjust shipping_priority based on region\n",
    "for i in range(num_rows):\n",
    "    if region[i] == 'North':\n",
    "        shipping_priority[i] = np.random.choice(['Low', 'Medium', 'High'], p=[0.1, 0.3, 0.6])\n",
    "    elif region[i] == 'South':\n",
    "        shipping_priority[i] = np.random.choice(['Low', 'Medium', 'High'], p=[0.3, 0.5, 0.2])\n",
    "    elif region[i] == 'East':\n",
    "        shipping_priority[i] = np.random.choice(['Low', 'Medium', 'High'], p=[0.4, 0.4, 0.2])\n",
    "    elif region[i] == 'West':\n",
    "        shipping_priority[i] = np.random.choice(['Low', 'Medium', 'High'], p=[0.5, 0.3, 0.2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrame creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = {\n",
    "    \"order_id\": order_id,\n",
    "    \"customer_id\": customer_id,\n",
    "    \"product_id\": product_id,\n",
    "    \"quantity\": quantity,\n",
    "    \"price\": price,\n",
    "    \"discount\": discount,\n",
    "    \"order_date\": order_date,\n",
    "    \"shipping_priority\": shipping_priority,\n",
    "    \"region\": region\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sales)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‘· 2. Introduction of noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce ruido y valores faltantes en un 5% de las filas siguiendo estos criterios: \n",
    "- En al menos tres columnas aleatorias por fila. \n",
    "- Opciones para ruido: eliminar valores, introducir cadenas como \"NULL\", o \n",
    "nÃºmeros extremos (ej. -9999). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_rows = df.sample(n=int(noise_percent * num_rows)).index\n",
    "columns = df.columns.tolist()\n",
    "columns.remove('order_id')  # I'll keep 'order_id' intact to maintain the primary key.\n",
    "\n",
    "for idx in noisy_rows:\n",
    "    noisy_columns = random.sample(columns, 3)\n",
    "    for col in noisy_columns:\n",
    "        #print(\"Adding noise to (row,col):\", (idx, col))\n",
    "        noise_type = random.choice(noise_options)\n",
    "        #print(df[col].dtype, type(noise_type))\n",
    "        df.at[idx, col] = random.choice(noise_options)\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ðŸ“Š 3. Saving results \n",
    "\n",
    "Guarda el dataset generado en raw_sales_data.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'../data/raw/raw_sales_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamart_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
